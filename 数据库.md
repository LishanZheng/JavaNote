# MySql

### 执行流程



## 索引

### 索引类型

1. 主键索引

2. 二级索引（辅助索引）

   1. 唯一索引，一张表允许多个唯一索引，唯一索引表示的列不能有重复值。主要用来唯一性的保证。数据可以为NULL
   2. 普通索引， 该列元素可以重复、为NULL，作用主要用来快速查询数据，
   3. 前缀索引，只适用于字符串类型的数据，对文本的前几个字符进行索引，比普通索引建立的数据小。
   4. 全文索引，为了检索大文本数据中的关键字信息。

3. 覆盖索引

   如果一个索引包含了所有需要查询的字段就称为覆盖索引。

4. 聚簇索引和非聚簇索引

   聚簇表示节点包含了索引和数据，非聚簇表示只包含了索引。要找到具体数据还要进行回表。

5. 联合索引

   使用多个字段进行索引。

### 建立索引需要注意什么

索引的建立需要消耗大量资源

1. 大量重复的字段不要建索引
2. 少量数据不要
3. 没有标示作用的字段不要建索引
4. 经常更新的字段不要建索引，会导致B+树不断的进行维护产生大量开销。
5. 字符串上使用前缀索引代替普通索引
6. 尽可能考虑联合索引，而不是单列索引。
7. 需要频繁排序的字段，可以建立索引，利用索引来加速排序查询。
8. 经常作为条件判断的字段，应该被考虑作为索引。

### 索引优化

1. 前缀索引优化

   通过前缀索引优化，可以减少索引字段大小，但是也有局限性：1.无法进行覆盖索引，2.orderby就无法使用前缀索引

2. 覆盖索引优化

   合理设置索引，让覆盖索引生效，从而避免回表

3. 主键自增

   因为innodb默认使用聚簇索引，数据被放到B+树的节点上，B+树的同一节点内的数据是按主键顺序存放的，因此如果有新的数据进来，会根据主键值放到对应位置。使用自增主键可以使每次插入的数据都会按顺序添加到新位置，不用移动原来的数据。

4. 防止索引失效

   1. 当使用like 模糊匹配时，索引会失效
   2. 对查询条件使用函数时，会失效
   3. 对于联合索引，需要注意左匹配原则，否则会失效
   4. 在Where字句中，OR前面使用索引字段，OR后面不是索引列，会导致失效。



## 事务

### 隔离等级

1. 读取未提交

   脏读、不可重复读、幻读

2. 读取已提交

   不可重复读、幻读

3. 可重复读

   幻读

4. 可串行化

### 四大特性

1. 原子性
2. 隔离性
3. 持久性
4. 一致性

### 多版本并发控制MVCC

基本组成：

- 隐藏列

  - 最后一个事务的ID DB_TRX_ID
  - undo日志的指针，指向旧版本的数据

- Read View

  - 事务最小ID，当前活跃事务的最小id
  - 事务最大ID，数据库给下一个事务的ID
  - 活跃事务ID列表，在创建Read View时活跃的事务列表ID
  - 创建该ReadView 的事务ID

- 回滚日志 undo log

  

可见性判断流程

1. 比较当前记录的 最后事务ID 是否小于事务最小ID，小于则可见

2. 比较当前记录的 最后事务ID是否大于事务最大ID，大于则不可见

3. 查询当前记录的最后事务ID，是否在活跃列表中：在的话不可见/ 不在的话可见

4. 对于不可见的都需要去找旧版本的可见数据来返回。

   1. 通过undo日志的指针，往前找版本，然后重新进行可见性判断。直到可见。

   

- 读已提交

  在一个事务中，每次查询都会新建一个Read View

- 可重复读

  在一个事务中，只会在第一次查询时新建一个Read View

- 在当前读情况下的幻读

  使用next-key锁 = 行锁+ 间隙锁

  

## 锁

### 锁的类型

- 全局锁

  

- 表级锁

  1. 表锁

  2. 意向锁

     在对某些记录尝试加载共享锁/独占锁时，需要先在表上申请到对应的意向共享锁/意向独占锁。

     方便添加表锁，不需要再挨个记录判断是否被添加了行级的共享/独占锁了

- 行级锁

  1. 记录锁 record lock，用锁住单个记录

  2. 间隙锁 gao lock，用来锁住一个范围内，不包括自己

  3. 临键锁 nextkey lock，锁定一个范围，包括自己（record lock + gap lock）

     

### 如何加锁 （next key lock）

next-key lock在不同情况下会退化为记录锁、间隙锁

- 唯一索引等值查询
  1. 没找到值：next-key lock 的右区间为空，变为了间隙锁。
  2. 找到值：退化为记录锁
- 唯一索引范围查询
  1. 没找到的那一部分：从next-key lock变为间隙锁
  2. 找到的部分：从next-key lock变为记录锁
- 非唯一索引等值查询
  		1. 没找到：退化为间隙锁
  		1. 找到：找到的next-key lock锁保持，因为非唯一还向后加上间隙锁

- 非唯一索引范围查询

  		1. 找到的部分：next-key lock+向后的间隙锁
  		1. 没找到的部分：因为是普通索引范围查找查找所以继续保持next-key lock

  

- insert语句加锁

  当insert事务需要加锁时，这个锁不可能发生冲突就会加一个隐式锁，在一些场景下会提升为显示锁

  1. 如果记录之间加有间隙锁，为避免幻读，需要变为显示锁

     插入数据时，下一条数据是否被加上了间隙锁，如果有的话就应该被阻塞，然后生成一个插入意向锁。

  2. 如果insert的记录和已有记录之间发生唯一键的冲突，就会提升为显示锁。

     如果插入的数据唯一键冲突了，就需要对这条记录加上S型的锁（可能记录锁、next-key锁）

     - 如果主键值重复
     - 如果唯一二级索引重复
     - // todo



### innoDB解决幻读

- 快照读，通过MVCC来保证不会幻读

  快照读：如果读取的数据正在进行update/delete操作，读取操作不会等待独占锁的释放，而是转而读取一个快照

- 当前读，通过next key lock来保证不会幻读

  当前读：读取的是最新提交的数据



## 日志

### binlog 二进制日志

（逻辑日志），记录语句的原始逻辑，（比如给id=2的这一行c字段+1）

用来数据备份、同步数据，保证数据一致性

- 记录格式

  1. statement格式

     记录的SQL语句原文，可能的问题：函数可能执行的结果和当前环境有关。导致数据不一致。（时间函数）

  2. row格式

     记录操作的具体数据，它记录看不到详细信息，要通过mysqlbinlog工具解析出来，它比较占空间

  3. mixed格式

     前两种的结合，如果statement格式会导致不一致问题，就使用row格式

- 写入时机

  事务执行时会把binlog日志写入binlog cache区中，事务提交时再把缓存区中的写入binlog 文件中。

  ​	如果存储的内容大于binlog cache的大小，就要暂存到磁盘中

  通过sync_binlog变量可以控制 写入page cache文件系统缓冲区的时机、和持久化到硬盘的时机

  0: 每次提交事务都只写入文件缓冲区、由系统决定什么时候持久化到硬盘。（机器宕机会丢失文件缓冲区的数据）

  1: 每次提交事务都写入缓冲区并且持久化到硬盘。

  N: 每次提交事务都写入文件缓冲区，但是每N个事务才进行持久化。

###  两阶段提交

- 原因：redo log重做日志和binlog 二进制日志的写入时机不一样，redolog是在事务过程中可以不断写，而binlog需要在事务提交后进行写入。如果在中间过程中出现异常，就会导致两个日志的数据不一致，导致主从的不一致，redo log影响主库数据、binlog影响从库数据。

- 具体操作：
  - 把redo log的操作分为两个部分 prepare + commit。
  - 事务提交后进入prepare阶段
  - prepare阶段：redo log 对应的事务状态设置为prepare 。redo log 正常写入磁盘。
  - commit阶段：写入binlog，然后binlog写入磁盘。然后提交事务，将事务状态设置为commit。刷入到硬盘redo log文件中
- 异常重启可能的情况
  - Mysql会扫描redo log文件，碰到prepare状态的redo log，就会去binlog中找这个事务ID，
    - 找到的话：说明binlog和redolog都已经刷盘完成，提交事务。
    - 没找到：说明redolog完成刷盘、binlog还没刷盘，进行回退事务。
- 两阶段提交可能的问题
  - I/O次数比较高，对应redo log 和binlog 双1的设置下，每次事务提交都会进行两次刷盘。
  - 锁竞争激烈，两阶段提交虽然可以保证单事务下的redolog和binlog一致性，但是对于多事务需要锁来保证一致性。
- 组提交
  - 当有多个事务时，会将多个binlog刷盘操作合并为一个，
  - 修改commit阶段：
    - 



### redo log 重做日志 （InnoDB）

记录在某个页面上做了什么操作。（物理日志）

- 实现事务的持久性

binlog是innoDB存储引擎特有的，使数据库具有崩溃恢复能力

- 什么时候进行记录

MySql中数据是以页为单位，查询一条记录会把一页的数据加载出来。放入缓冲池buffer pool中。查询都是先从缓冲池中找，没有命中才去数据库。更新时也是先更新到buffer pool中，然后会把这个更新记录到redo log buffer中，然后刷盘或者写到redo log 文件中。

- 刷盘时机

  - 提供了innodb_flush_log_at_trx_commit有三个参数：

    0:提交事务后不刷盘

    1:每次提交事务都刷盘（默认） 

    2:每次提交事务都把缓冲区的数据放入page cache中

  - InnoDB有一个后台线程，

    - 每隔1秒都会把redo log buffer中的数据写到文件缓冲系统（page cache）中。然后fsync刷盘
    - 或者当redo log buffer的空间达到一半时，也会进行主动刷盘

- 日志文件组

​		硬盘上的redo log日志不止一个，是以日志组的形式，是循环写，



### undo log 回滚日志

- 实现事务的原子性

- 在事务没提交前， 先将更新前的数据记录到undo log中，当事务回滚时，里用undo log来回滚。
- 结构：
  - 记录的数据
  - 指针，指向历史版本的回滚日志
  - 事务id，可以知道该记录由那个事务修改的。
- 生命周期
  - 产生：在事务开始之前
  - 销毁：事务提交之后，并不会马上删除undo log，而是放入待删除的列表，由purge线程判断是否有其他事务使用undo段的上一个事务之前的版本信息，





# Redis

### 高可用的实现

- 数据持久化（保证数据不丢失）
  1. RDB-快照：将某个时刻Redis的的内存数据以二进制的形式写入硬盘，占用空间小，但是有数据丢失的风险
  2. AOF 文件：将所有操作命令，以文本追加的形式写入文件中，存储频率高，但是占用空间大。
  3. 混合模式：一开始使用RBD形式存储，之后的命令使用AOF文件进行追加

- 主从复制（单机变为多机）

  实现读写分离，只有主节点进行写操作，从节点只能读操作。

  1. 主从模式：一个主节点和多个从节点
  2. 从从模式：从节点可以继续往下拥有更多的从节点

- Redis哨兵模式（自动容灾）

  用来监控主从服务器，当主从服务器有问题进行自动容灾修复。

- Redis集群（Cluster）（分布式扩展）

  拥有多个主节点，然后主节点有各自的从节点。

  通过数据分片，自动把数据分割到不同master节点上。有2^14个哈希槽，一个key通过CRC16校验后对16384取模决定放在那个槽中



### 主从复制

- 第一次同步（全量复制）

  第一次同步为全量同步，分为三个阶段。

  1. 建立主从的连接，协商同步

  2. 主服务器同步数据给从服务器

     - 主服务器执行bgsave命令生成RDB文件，然后从服务器清空数据，接受文件写入数据

     - bgsave命令由子线程执行，这时主线程依然正常处理命令。

       生成RBD文件的过程中主线程处理的命令并不会写到RDB文件中，会写到replication buffer缓冲区中。

       1. 正在生成RDB文件时
       2. 发送RDB文件时
       3. 从服务器正在加载RDB文件时

  3. 主服务器发送新写命令给从服务器

     在从服务器加载完毕RDB文件后，会将replication buffer缓冲区的数据发送给从服务器。然后从服务器执行这些命令就可以保证一致性。

- 基于长连接的命令传播

  在第一次同步后，双方会维持一个长连接。（长连接：避免频繁的tcp连接和断开的性能开销）

  通过这个长连接，把主服务器执行的命令传播给从服务器执行，保证一致性

- 增量复制

  数据结构：

  1. repl_backlog_buffer：环形缓冲区，存储数据，用来找到差异的数据

     写入时机：当主服务器执行命令后，会将写命令发送给从服务器，并且存到repl_backlog_buffer中

  2. Replication_offset：同步进度的偏移量

     

  复制模式：

  当从节点断开并重新连接上主节点后，会将自己的偏移量告知主节点，主节点决定才用那种同步操作：

  1. 若偏移量还在repl_backlog_buffer 环形缓冲区中，就进行增量同步。
  2. 若偏移量已经不存在了，就使用全量同步

  

  环形缓冲区大小设置：

  从服务器掉线到重新连接的平均时间 X 每秒产生的命令数据量大小



### 哨兵模式

哨兵模式主要用来实现主从节点故障转移。

1. 监控

   - 监控节点

     每隔1s会发送PING命令给主从节点，节点收到后会发送一个响应命令给哨兵，进行监控。

   - 故障判断

     - 主观下线

       若主从节点收到ping命令后没有即使回复响应命令，哨兵就会标记它为主观下线。

     - 客观下线（只对主节点）

       当主节点被哨兵判断为主观下线后，其他哨兵会对它进行投票，如果达到quorum的值，就判断为客观下线。然后就需要进行选新的主节点

2. 选主并通知

   - 主从故障转移由那个哨兵进行？ ：将由判断主节点客观下线的那个哨兵作为候选者

     - 候选者选举为leader的条件

       候选者往其他的哨兵发送命令，每个哨兵进行投票，每个哨兵只能投一次票。当候选者获得的票数大于一半 且 大于等于quorum值 就会选举成功

     - 该哨兵进行主从故障转移

       1. 选择新主节点：从原来主节点下的从节点中选择一个最优秀的节点作为主节点（度量：优先级、复制进度、ID号）

          优先级：redis有个slave-priority配置项用来配置优先级

          复制进度：比较replication-offset 复制进度

          ID号：ID号小胜出

       2. 将从节点指向新的主节点

          哨兵向所有从节点发送命令SLAVEOF，让它们成为新主节点的从节点

       3. 通知客户主节点被更换

          通过Redis的发布者/订阅者机制，将主节点的ip地址和端口信息进行发布。客户端会订阅这些信息。

       4. 旧主节点变为从节点

          当旧的主节点上线后，需要将它变为从节点，



### 对比Redis和Memcached

#### 相同点

1. 都在内存中，速度很快可以作为缓存使用。

     		2.  都有过期策略。
  		3.  性能很高

#### 不同点

1. Redis有原生的集群模式，Memcached没有
2. Redis支持事务、Lua脚本、订阅模型等。Memcached没有。
3. Redis可以进行持久化到磁盘，Memcached没有。
4. Redis可以支持复杂的数据存储，Memcached只有key-value模型

### 线程模型

redis并不是单线程的，包括了一个主线程，和三个后台线程（AOF刷盘、关闭文件、释放内存）

### Redis的持久化

1. AOF刷盘，每次执行一条写命令，都将它存入AOF文件用于恢复。

1. RDB快照，将某一时刻的内存数据，以二进制的形式写入磁盘。
2. 混合模式，Redis4.0新增的方式。

### AOF （append only file）

先执行完一条写命令后，在执行记录命令

* Question：为什么先执行写命令，在执行记录日志命令？

  * Answer

    好处

    1. 可以避免检查命令正确性的开销，每次写命令执行成功后才会写入日志。
    2. 不会阻塞写命令的执行。

    坏处

    1. 可能会丢失数据，因为是分开执行的，所有如果在执行完写命令后服务宕机，会导致这次的写入没有保存。
    2. 会阻塞其他命令的执行。因为AOF日志也是在主线程中执行的，在写入磁盘的时候，主线程就无法执行其他命令了。

* 具体说说如何记录？

  * 执行完写命令后，先将命令追加到aof buf中。
  * 然后将aof buf中的数据复制到内核区的缓冲区page cache。
  * 然后由内核决定什么时候把缓冲区的数据写入硬盘

* Question：Redis有几种写入硬盘的策略？

  1. Always 及时写回，每次都直接写回去。
  2. Everysec 每秒写回，每隔一秒写回去。
  3. No 不由redis控制，意味着由操作系统自己控制什么时候把缓存区的数据写入内核。
  
* Question：AOF文件太大怎么办？

  * 有AOF重写机制，当AOF文件过大时，会将当前内存中的键值对全部写入一个《新的AOF文件》中，然后替换掉现在过大的AOF文件。相对于压缩了AOF文件。

#### AOF重写机制

AOF重写由《子进程》bgrewriteaof来完成。触发AOF重写机制后，主进程会创建子进程，由这个子进程对内存进行只读操作，并将键值对转为命令存入AOF文件中。

* 由子进程完成有什么好处？
  1. 主线程可以继续执行其他任务，减少了阻塞。
  2. 由进程的形式来处理，可以减少不必要的加锁开销，子进程会复制父进程的数据，并且当父子双发任意一方修改了内存，都会发生《写时复制》让父子进程有各自独立的数据副本保证数据安全。
* Question：AOF重写过程可能存在数据不一致问题怎么办？
  * Redis设置了《AOF重写缓冲区》，在处于重写阶段后会被使用，每次Redis执行完写命令后都会追加到《AOF重写缓冲区》中，当子进程读取完所有键值对后，在把《AOF重写缓冲区》中的数据追加到<AOF文件>中即可。